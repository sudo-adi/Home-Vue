//import Foundation
//import ARKit
//import FocusEntity
//import RealityKit
//import SwiftUI
//import Combine
//import Photos
//
//class CustomARView: ARView {
//    var focusEntity: FocusEntity!
//    var sessionSettings: SessionSettings
//    
//    @State private var toastMessage: String = ""
//    @State private var showToast: Bool = false
//    
//    private var peopleOcclusionCancellable: AnyCancellable?
//    private var objectOcclusionCancellable: AnyCancellable?
//    private var lidarDebugCancellable: AnyCancellable?
//    
//    required init(frame frameRect: CGRect, sessionSettings: SessionSettings){
//        self.sessionSettings = sessionSettings
//        
//        super.init(frame: frameRect)
//        
//        focusEntity = FocusEntity(on: self, focus: .classic)
//        
//        configure()
//        
//        self.initializeSettings()
//        
//        self.setupSubscribers()
//    }
//    
//    required init(frame frameRect: CGRect){
//        fatalError("init(frame:) has not been implemented")
//    }
//    
//    @objc required dynamic init?(coder decoder: NSCoder){
//        fatalError("init(coder:) has not been implemented")
//    }
//    
//    private func configure() {
//        let config = ARWorldTrackingConfiguration()
//        config.planeDetection = [.horizontal, .vertical]
//
//        if ARWorldTrackingConfiguration.supportsSceneReconstruction(.mesh) {
//            config.sceneReconstruction = .mesh
//            config.environmentTexturing = .automatic
//            
//            // Set the scene's physics origin to world space
////            self.environment.physicsOrigin = .world
//        }
//        
//        // Start with a clean session
//        session.run(config, options: [.resetTracking, .removeExistingAnchors])
//    }
//    
//    func pauseSession() {
//       session.pause()
//       focusEntity.isEnabled = false
//       print("AR session paused")
//   }
//   
//   func resetSession() {
//       let config = ARWorldTrackingConfiguration()
//       config.planeDetection = [.horizontal, .vertical]
//       config.sceneReconstruction = .mesh
//       config.environmentTexturing = .automatic
//       session.run(config, options: [.resetTracking, .removeExistingAnchors])
//       print("AR session reset")
//   }
//    
//    private func initializeSettings(){
//        self.updatePeopleOcclusion(isEnabled: sessionSettings.isPeopleOcclusionEnabled)
//        self.updateObjectOcclusion(isEnabled: sessionSettings.isObjectOcclusionEnabled)
//        self.updateLidarDebug(isEnabled: sessionSettings.isLidarDebugEnabled)
//    }
//    
//    private func setupSubscribers() {
//        self.peopleOcclusionCancellable = sessionSettings.$isPeopleOcclusionEnabled.sink { [weak self] isEnabled in
//            self?.updatePeopleOcclusion(isEnabled: isEnabled)
//        }
//        
//        self.objectOcclusionCancellable = sessionSettings.$isObjectOcclusionEnabled.sink { [weak self] isEnabled in
//            self?.updateObjectOcclusion(isEnabled: isEnabled)
//        }
//        
//        self.lidarDebugCancellable = sessionSettings.$isLidarDebugEnabled.sink { [weak self] isEnabled in
//            self?.updateLidarDebug(isEnabled: isEnabled)
//        }
//    }
//    
//    func setupLighting() {
//        // Enable automatic environment lighting
//        environment.sceneUnderstanding.options = [.occlusion, .physics]
//        
//        // Add directional light
//        let directionalLight = DirectionalLight()
//        directionalLight.light.intensity = 1000
//        directionalLight.shadow = DirectionalLightComponent.Shadow(
//            maximumDistance: 4,
//            depthBias: 2
//        )
//        
//        // Position the light
//        directionalLight.look(at: [0, 0, 0], from: [1, 1.5, 1], relativeTo: nil)
//        
//        // Create anchor for lights
//        let lightAnchor = AnchorEntity(.world(transform: .init(diagonal: [1,1,1,1])))
//        lightAnchor.addChild(directionalLight)
//        
//        scene.addAnchor(lightAnchor)
//    }
//
//    
//    private func updatePeopleOcclusion(isEnabled: Bool) {
//        print("\(#file)): isPeopleOcclusionEnabled is now \(String(describing: isEnabled).uppercased())")
//        
//        // Verify device support for People Occlusion
//        guard ARWorldTrackingConfiguration.supportsFrameSemantics(.personSegmentationWithDepth) else {
//            return
//        }
//        
//        // Obtain the AR Session current configuration
//        guard let configuration = self.session.configuration as? ARWorldTrackingConfiguration else {
//            return
//        }
//        
//        // Enable/disable People Occlusion by adding/removing the personSegmentationWithDepth option to/from the configurationâ€™s frame semantics.
////        if configuration.frameSemantics.contains(.personSegmentationWithDepth) {
////            configuration.frameSemantics.remove(.personSegmentationWithDepth)
////        } else {
////            configuration.frameSemantics.insert(.personSegmentationWithDepth)
////        }
//        if isEnabled {
//                configuration.frameSemantics.insert(.personSegmentationWithDepth)
//            } else {
//                configuration.frameSemantics.remove(.personSegmentationWithDepth)
//            }
//        
//        // Rerun the session to affect the configuration change.
//        self.session.run(configuration)
//    }
//
//    private func updateObjectOcclusion(isEnabled: Bool) {
//        print("\(#file): isObjectOcclusionEnabled is now \(String(describing: isEnabled).uppercased())")
//        
//        // Verify device support for Object Occlusion
//        guard ARWorldTrackingConfiguration.supportsSceneReconstruction(.mesh) else {
//            print("Device doesn't support scene reconstruction with mesh")
//            return
//        }
//        
//        // Obtain the AR Session current configuration
////        guard let configuration = self.session.configuration as? ARWorldTrackingConfiguration else {
////            print("Failed to get AR configuration")
////            return
////        }
//        let configuration = ARWorldTrackingConfiguration()
//        configuration.planeDetection = [.horizontal, .vertical]
//        configuration.environmentTexturing = .automatic
//        // Enable mesh reconstruction first (required for object occlusion)
//        configuration.sceneReconstruction = .mesh
//        
//        // Set object occlusion state based on the isEnabled parameter
//        if isEnabled {
//            self.environment.sceneUnderstanding.options.insert([.occlusion, .receivesLighting])
//            // You might also need to set additional occlusion-related options
////            configuration.environmentTexturing = .automatic
//        } else {
//            self.environment.sceneUnderstanding.options.remove([.occlusion, .receivesLighting])
//        }
//        
//        // Add more detailed debugging information
//        print("Scene understanding options: \(self.environment.sceneUnderstanding.options)")
//        
//        // Rerun the session to affect the configuration change
////        self.session.run(configuration, options: [.resetSceneReconstruction])
////        self.session.run(configuration, options: [.resetTracking, .removeExistingAnchors, .resetSceneReconstruction])
//        let options: ARSession.RunOptions = isEnabled ? [] : [.resetTracking, .removeExistingAnchors]
//        self.session.run(configuration, options: options)
//    }
//    
//
//    private func updateLidarDebug(isEnabled: Bool) {
//        print("\(#file): isLidarDebugEnabled is now \(String(describing: isEnabled).uppercased())")
//        
//        // Verify device support for LiDAR
//        guard ARWorldTrackingConfiguration.supportsSceneReconstruction(.mesh) else {
//            return
//        }
//        
//        // Obtain the AR Session current configuration
//        guard let configuration = self.session.configuration as? ARWorldTrackingConfiguration else {
//            return
//        }
//        
//        // Set LiDAR debug visualization state based on the isEnabled parameter
//        if isEnabled {
//            self.debugOptions.insert(.showSceneUnderstanding)
//        } else {
//            self.debugOptions.remove(.showSceneUnderstanding)
//        }
//        
//        // Rerun the session to affect the configuration change if needed
//        self.session.run(configuration)
//    }
//}
import Foundation
import ARKit
import FocusEntity
import RealityKit
import SwiftUI
import Combine

class CustomARView: ARView {
    var focusEntity: FocusEntity!
    
    required init(frame frameRect: CGRect) {
        super.init(frame: frameRect)
        
        focusEntity = FocusEntity(on: self, focus: .classic)
    }
    
    @objc required dynamic init?(coder decoder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
}
